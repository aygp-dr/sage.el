#+TITLE: sage.el - AI REPL with Tool Calling for Emacs
#+AUTHOR: Jason Walsh
#+EMAIL: j@wal.sh

[[https://www.gnu.org/software/emacs/][https://img.shields.io/badge/Emacs-28.1+-blueviolet.svg?style=flat-square]]
[[https://github.com/aygp-dr/sage.el/blob/main/LICENSE][https://img.shields.io/badge/license-GPL--3.0-blue.svg?style=flat-square]]
[[https://melpa.org/#/sage][https://img.shields.io/badge/MELPA-planned-orange.svg?style=flat-square]]

* Overview

=sage.el= is an Emacs package providing an interactive AI REPL with tool/function calling capabilities. It supports multiple LLM providers (Gemini, Ollama, OpenAI) with a local-first philosophy - use Ollama for free, private AI assistance.

| Provider | Local | API Key | Models |
|----------+-------+---------+--------|
| Ollama | Yes | No | llama3.2, mistral, qwen2.5 |
| Gemini | No | Yes | gemini-2.0-flash, gemini-1.5-pro |
| OpenAI | No | Yes | gpt-4o, gpt-4o-mini |

This is the Elisp version of [[https://github.com/aygp-dr/gemini-repl-009][gemini-repl-009]] (Rust implementation).

* Features

- *Multi-provider support*: Google Gemini, Ollama (local), OpenAI
- *Tool/function calling*: AI can use tools to interact with your system
- *Permission system*: Configurable prompts for dangerous operations
- *Rate limiting*: Automatic rate limiting per model with 90% safety margin
- *Built-in tools*:
  - File operations (read, write, list)
  - Git integration (status, diff, log, blame)
  - Code search via ripgrep
- *Session persistence*: Save and restore conversations
- *Project-based conversations*: Per-directory conversation history
- *Project-aware*: Workspace-scoped file operations
- *Emacs-native integrations*:
  - Org mode: Send subtrees, source blocks, AI blocks
  - Buffer operations: Send buffer, region, defun
  - Dired integration: Summarize files
  - Prog mode: Explain errors, suggest fixes
  - Minor mode with convenient keybindings

* Installation

** Prerequisites

- Emacs 28.1+
- =request.el= package (for HTTP)
- =ripgrep= (optional, for code search)

** Manual Installation

#+begin_src bash
git clone https://github.com/aygp-dr/sage.el ~/.emacs.d/site-lisp/sage
#+end_src

#+begin_src elisp
(add-to-list 'load-path "~/.emacs.d/site-lisp/sage")
(require 'sage)
#+end_src

** use-package

#+begin_src elisp
(use-package sage
  :load-path "~/.emacs.d/site-lisp/sage"
  :config
  (setq sage-api-key (getenv "GEMINI_API_KEY"))
  (setq sage-provider 'gemini))

;; Project-based conversation history (optional)
(use-package sage-project
  :after sage
  :config
  (setq sage-project-auto-load t)
  (setq sage-project-auto-save t))

;; Emacs-native integrations (optional)
(use-package sage-emacs
  :after sage
  :config
  (global-sage-mode 1))
#+end_src

* Configuration

** API Keys

#+begin_src elisp
;; For Gemini (or set GEMINI_API_KEY env var)
(setq sage-api-key "your-api-key")

;; For OpenAI (or set OPENAI_API_KEY env var)
(setq sage-openai-api-key "your-api-key")

;; For Ollama (no key needed, just ensure server is running)
(setq sage-ollama-host "http://localhost:11434")
#+end_src

** Provider Selection

#+begin_src elisp
;; Options: 'gemini, 'ollama, 'openai
(setq sage-provider 'gemini)

;; Model override (optional)
(setq sage-model "gemini-2.0-flash-exp")
#+end_src

** Permission Settings

#+begin_src elisp
;; Skip all permission checks (dangerous!)
(setq sage-yolo-mode nil)

;; Require confirmation even for read-only tools
(setq sage-confirm-safe-tools nil)

;; Maximum tool iterations per request
(setq sage-max-tool-iterations 10)
#+end_src

** Workspace

#+begin_src elisp
;; Set workspace for file operations (defaults to current directory)
(setq sage-workspace "/path/to/project")
#+end_src

* Usage

** Starting the REPL

#+begin_src
M-x sage
#+end_src

Type your message at the =>=  prompt and press =RET= to send.

** Key Bindings

| Key       | Command                | Description           |
|-----------+------------------------+-----------------------|
| =RET=     | sage-send-input | Send message          |
| =C-c C-k= | sage-clear      | Clear conversation    |
| =C-c C-c= | sage-interrupt  | Interrupt request     |

** Commands

- =M-x sage= - Start interactive REPL
- =M-x sage-exec= - Single-shot prompt execution
- =M-x sage-send-region= - Send selected region to AI

* Built-in Tools

| Tool        | Description                      | Safe? |
|-------------+----------------------------------+-------|
| read_file   | Read file contents               | Yes   |
| list_files  | List files in directory          | Yes   |
| write_file  | Write content to file            | No    |
| git_status  | Get git status                   | Yes   |
| git_diff    | Get git diff                     | Yes   |
| git_log     | Get git log                      | Yes   |
| code_search | Search code with ripgrep         | Yes   |
| glob_files  | Find files matching glob pattern | Yes   |

* Rate Limiting

=sage-ratelimit= provides automatic rate limiting to prevent exceeding API limits.

** Features

- Per-model rate tracking using ring buffers
- 90% safety margin (configurable)
- Automatic waiting with countdown display
- REPL commands for status checking
- Support for all major providers

** Model Limits

| Provider | Model                 | Limit (RPM) | Effective (90%) |
|----------+-----------------------+-------------+-----------------|
| Gemini   | gemini-1.5-flash-lite |          30 |              27 |
| Gemini   | gemini-1.5-flash      |          15 |              13 |
| Gemini   | gemini-1.5-pro        |           5 |               4 |
| Gemini   | gemini-2.0-flash-exp  |          10 |               9 |
| OpenAI   | gpt-4o                |          10 |               9 |
| OpenAI   | gpt-4o-mini           |          30 |              27 |
| Ollama   | All models            |   Unlimited |       Unlimited |

** Usage

Rate limiting is automatic. Check status in REPL:

#+begin_example
> /ratelimit
gemini-2.0-flash-exp: 3/9 requests used (33% limit). Ready

> /ratelimit-reset
Rate limit reset for gemini-2.0-flash-exp
#+end_example

For more details, see [[file:RATELIMITING.org][RATELIMITING.org]].

* Project-Based Conversations

=sage-project.el= provides per-directory conversation history management, allowing each project to maintain its own persistent conversation context.

** Features

- *Per-directory storage*: Each project has isolated conversation history
- *Auto-load*: Conversations automatically load when starting REPL
- *JSONL format*: Efficient append-only storage format
- *Archive support*: Archive old conversations while keeping history
- *Project metadata*: Track creation, updates, message counts, etc.
- *Multiple backends*: Works with project.el, projectile, or git

** Storage Structure

#+begin_example
~/.emacs.d/sage/projects/
├── -home-user-project1/
│   ├── conversation.jsonl   # Current conversation
│   ├── metadata.json        # Project metadata
│   └── history/            # Archived conversations
└── -home-user-project2/
    └── ...
#+end_example

** Configuration

#+begin_src elisp
(require 'sage-project)

;; Enable auto-load and auto-save
(setq sage-project-auto-load t)
(setq sage-project-auto-save t)

;; Set maximum messages before auto-archive
(setq sage-project-max-messages 1000)

;; Prefer projectile over project.el
(setq sage-project-prefer-projectile nil)
#+end_src

** Usage

#+begin_src elisp
;; Load conversation for current project
(sage-project-load)

;; Append a message
(sage-project-append '("user" "How do I optimize this?"))

;; Clear conversation (archives first)
(sage-project-clear)

;; Archive current conversation
(sage-project-archive "before-refactor")

;; List archives
(sage-project-list-archives)

;; Load an archive
(sage-project-load-archive "20241223-140530.jsonl")

;; Display statistics
(sage-project-stats)

;; Export to JSON or Markdown
(sage-project-export "conversation.json" 'json)
(sage-project-export "conversation.md" 'markdown)
#+end_src

See [[file:PROJECT-SESSIONS.org][PROJECT-SESSIONS.org]] for detailed documentation.

* Context Management

=sage-context.el= provides token counting and context window management to prevent exceeding provider limits.

** Features

- *Token estimation*: Rough character-based heuristic (chars/4)
- *Role tracking*: Count tokens separately for user, assistant, and function messages
- *Usage monitoring*: Automatic warnings at 80%, compaction at 90%
- *Multiple strategies*:
  - Sliding window: Keep most recent N messages
  - Summarization: Use LLM to summarize old messages
  - Hybrid: Combine both approaches
- *Provider limits*: Pre-configured limits for Gemini, OpenAI, Ollama models

** Configuration

#+begin_src elisp
(require 'sage-context)

;; Set warning and compaction thresholds
(setq sage-context-warning-threshold 0.80)      ; Warn at 80%
(setq sage-context-compaction-threshold 0.90)   ; Compact at 90%

;; Enable automatic compaction
(setq sage-context-auto-compact t)

;; Choose default strategy
(setq sage-context-default-strategy 'sliding-window)
;; Options: 'sliding-window, 'summarization, 'hybrid

;; Configure sliding window size
(setq sage-context-window-size 20)
#+end_src

** Usage

#+begin_src elisp
;; Show context status
(sage-context-status)

;; Manually compact conversation
(sage-context-compact-now)

;; Check token usage
(sage-context-tokens messages)
(sage-context-usage messages)
#+end_src

** Provider Token Limits

| Provider          | Model              | Max Tokens |
|-------------------+--------------------+------------|
| Google Gemini     | gemini-1.5-pro     |  1,000,000 |
| Google Gemini     | gemini-1.5-flash   |    128,000 |
| Google Gemini     | gemini-2.0-flash   |    128,000 |
| OpenAI            | gpt-4o             |    128,000 |
| OpenAI            | gpt-4o-mini        |    128,000 |
| Ollama            | llama3.2           |      8,192 |
| Ollama            | llama3.1           |    128,000 |
| Default (unknown) | -                  |      8,192 |

* Custom Tools

Register custom tools:

#+begin_src elisp
(sage-register-tool
 "my_tool"
 "Description of what the tool does"
 '((type . "object")
   (properties . ((arg1 . ((type . "string")
                          (description . "First argument")))))
   (required . ["arg1"]))
 (lambda (args)
   (let ((arg1 (alist-get 'arg1 args)))
     (format "Result for %s" arg1))))
#+end_src

* Emacs-Native Integrations (sage-emacs.el)

The =sage-emacs= package provides deep integration with Emacs modes and workflows.

** Org Mode Integration

| Function                           | Description                              | Keybinding     |
|------------------------------------+------------------------------------------+----------------|
| =sage-org-send-subtree=     | Send current org subtree as context      | =C-c C-g o s=  |
| =sage-org-send-src-block=   | Send org source block to AI              | =C-c C-g o c=  |
| =sage-org-insert-response=  | Insert response as org AI block          | =C-c C-g o i=  |
| =sage-org-process-ai-blocks= | Process all #+begin_ai blocks in buffer | =C-c C-g o p=  |

*** AI Blocks in Org Mode

You can use special blocks in your org documents:

#+begin_example
#+begin_ai
Explain the key concepts in this document
#+end_ai
#+end_example

Use =M-x sage-org-process-ai-blocks= to process all blocks and insert responses.

** Buffer Integration

| Function                          | Description                    | Keybinding   |
|-----------------------------------+--------------------------------+--------------|
| =sage-send-buffer=         | Send entire buffer to AI       | =C-c C-g b=  |
| =sage-send-region-improved= | Send selected region           | =C-c C-g g=  |
| =sage-send-defun=          | Send current function          | =C-c C-g d=  |
| =sage-insert-response=     | Insert last response at point  | =C-c C-g i=  |
| =sage-ask-about-buffer=    | Ask question about buffer      | =C-c C-g a=  |
| =sage-ask-about-project=   | Ask question about project     | =C-c C-g p=  |

** Dired Integration

When in Dired mode, additional commands are available:

| Function                        | Description                | Keybinding   |
|---------------------------------+----------------------------+--------------|
| =sage-dired-summarize=   | Summarize marked files     | =C-c C-g s=  |
| =sage-dired-describe-file= | Describe file at point   | =C-c C-g d=  |

** Prog Mode Integration

Available in all programming modes:

| Function                      | Description                        | Keybinding   |
|-------------------------------+------------------------------------+--------------|
| =sage-explain-error=   | Explain error at point with context | =C-c C-g x=  |
| =sage-suggest-fix=     | Suggest fix for code at point      | =C-c C-g f=  |
| =sage-explain-at-point= | Explain symbol/code at point       | =C-c C-g e=  |

** Compilation Mode Integration

In compilation buffers:

| Function                             | Description              | Keybinding   |
|--------------------------------------+--------------------------+--------------|
| =sage-explain-compilation-error= | Explain compilation error | =C-c C-g e=  |

** Minor Mode

Enable =sage-mode= to activate all keybindings:

#+begin_src elisp
;; Enable globally
(global-sage-mode 1)

;; Or enable for specific buffers
(add-hook 'emacs-lisp-mode-hook #'sage-mode)
(add-hook 'python-mode-hook #'sage-mode)
#+end_src

** Customization

#+begin_src elisp
;; Type of org block for AI interactions
(setq sage-emacs-org-ai-block-type "ai")

;; Insert responses as comments in code buffers
(setq sage-emacs-insert-as-comment t)

;; Lines of context for error explanations
(setq sage-emacs-context-lines 5)

;; Auto-format responses based on mode
(setq sage-emacs-auto-format-response t)
#+end_src

** Complete Keybinding Reference

All keybindings use the =C-c C-g= prefix:

| Key         | Command                               | Context      |
|-------------+---------------------------------------+--------------|
| =C-c C-g r= | Open REPL                             | Global       |
| =C-c C-g g= | Send region                           | Global       |
| =C-c C-g b= | Send buffer                           | Global       |
| =C-c C-g d= | Send defun                            | Global       |
| =C-c C-g e= | Explain at point                      | Global       |
| =C-c C-g i= | Insert response                       | Global       |
| =C-c C-g a= | Ask about buffer                      | Global       |
| =C-c C-g p= | Ask about project                     | Global       |
| =C-c C-g x= | Explain error                         | Prog modes   |
| =C-c C-g f= | Suggest fix                           | Prog modes   |
| =C-c C-g o s= | Send org subtree                    | Org mode     |
| =C-c C-g o c= | Send org source block               | Org mode     |
| =C-c C-g o i= | Insert org AI block                 | Org mode     |
| =C-c C-g o p= | Process org AI blocks               | Org mode     |
| =C-c C-g s= | Summarize files                       | Dired        |
| =C-c C-g d= | Describe file                         | Dired        |

* Security

The package includes several security measures:

1. *Path validation*: File operations are restricted to the workspace
2. *Traversal protection*: =..= paths are rejected
3. *Sensitive file blocking*: =.env=, =.git/=, =.ssh/= are protected
4. *Permission prompts*: Dangerous operations require confirmation

* Comparison with Other Tools

| Feature          | sage.el | Claude Code | Efrit | Aider |
|------------------+----------------+-------------+-------+-------|
| Emacs native     | Yes            | No          | Yes   | No    |
| Multi-provider   | Yes            | No          | No    | Yes   |
| Tool calling     | Yes            | Yes         | Yes   | Yes   |
| Local inference  | Yes (Ollama)   | No          | No    | Yes   |
| Permission system| Yes            | Yes         | Yes   | Yes   |

* Contributing

Contributions welcome! Please see the GitHub repository for issues and pull requests.

* License

GPL-3.0 (to be compatible with Emacs)

* See Also

- [[https://github.com/aygp-dr/gemini-repl-009][gemini-repl-009]] - Rust implementation
- [[https://github.com/steveyegge/efrit][Efrit]] - AI-Powered Emacs Coding Assistant
- [[https://aider.chat][Aider]] - AI Pair Programming
