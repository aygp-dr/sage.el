# sage.el environment configuration
# Copy this file to .env and fill in your API keys

# Gemini API key (get one at https://aistudio.google.com/app/apikey)
GEMINI_API_KEY=your-gemini-api-key-here

# OpenAI API key (optional, get one at https://platform.openai.com/api-keys)
# OPENAI_API_KEY=your-openai-api-key-here

# Ollama runs locally and doesn't require an API key
# Default endpoint: http://localhost:11434
